{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1002f757e32d>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/humbapumba/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/humbapumba/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/humbapumba/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/humbapumba/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/humbapumba/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot = True)\n",
    "\n",
    "#Utilizamos one_hot, esto nos facilita la manera en que manejamos las etiquetas (nos regresa un vector con \n",
    "# tamaño de la dimension de las etiquetas (en este caso 10), con todos los valores en 0, exeptuando 1\n",
    "# Ejemplo: \n",
    "# (Numero 4)\n",
    "# [0.0.0.0.1.0.0.0.0.0]\n",
    "# (Numero 9)\n",
    "# [0.0.0.0.0.0.0.0.0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55000 training examples\n",
      "There are 5000 validation examples\n",
      "There are 10000 test examples\n",
      "Size  of images (as array) 784\n",
      "10 labels\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print('There are %s training examples' %mnist.train.images.shape[0])\n",
    "\n",
    "print('There are %s validation examples' %mnist.validation.images.shape[0])\n",
    "\n",
    "print('There are %s test examples'  %mnist.test.images.shape[0])\n",
    "\n",
    "print('Size  of images (as array) %s' %mnist.train.images.shape[1])\n",
    "\n",
    "print('%s labels' %mnist.train.labels.shape[1])\n",
    "\n",
    "##10 labels (0,1,2,3,4,5,6,7,8,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muestra_digito(x):\n",
    "    \"\"\"\n",
    "        x: vector \n",
    "            784 dimensiones\n",
    "        Muestra el vector como una imágen de 28x28\n",
    "    \"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def vis_img(i, conjunto=\"train\"):\n",
    "    \"\"\"\n",
    "        i indice del conjunto especificado\n",
    "        conjunto: cadena\n",
    "            Cualquiera: train, validation, test\n",
    "            \n",
    "        Muestra el dígito en el indice i  y su etiqueta\n",
    "    \"\"\"\n",
    "    if(conjunto==\"train\"): \n",
    "        muestra_digito(mnist.train.images[i,])\n",
    "        label = np.argwhere(mnist.train.labels[i])[0][0]\n",
    "    elif(conjunto==\"test\"): \n",
    "        muestra_digito(mnist.test.images[i,])\n",
    "        label = np.argwhere(mnist.test.labels[i])[0][0]\n",
    "    else:\n",
    "        muestra_digito(mnist.validation.images[i,])\n",
    "        label = np.argwhere(mnist.validation.labels[i])[0][0]\n",
    "    print(\"Etiqueta \" + str(label))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con 512 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "x = tf.placeholder(tf.float32,shape=[None,784]) #Ponemos la dimension del arreglo de las imagenes (784)\n",
    "y = tf.placeholder(tf.float32,shape=[None,10]) #La dimension de las labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creamos las capas de nuestra red neuronal (2 capas, una oculta y otra de salida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Capa 1\n",
    "#Matriz de pesos W_1\n",
    "W_1 = tf.Variable(tf.truncated_normal(shape = [784,512], stddev=0.2))## [Tamaño de los datos, numero de neuronas de la capa]\n",
    "#Vector de sesgos b_1\n",
    "b_1 = tf.Variable(tf.zeros([512]))\n",
    "\n",
    "\n",
    "\n",
    "#Capa de salida (2)\n",
    "W_2 =tf.Variable(tf.truncated_normal(shape = [512,10], stddev=0.2)) ##Tomamos el numero de datos que nos va a dar la capa anterior\n",
    "#en este caso 512 (por las 512 neuronas) y lo pasamos a 10 (nuestra capa de salida solo tiene 10 labels que son los digitos)\n",
    "##Si quisieramos agregar mas capas podriamos hacerlo\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x):\n",
    "    \n",
    "    ##Capa escondida 1\n",
    "    z_1 = tf.matmul(x,W_1) + b_1 #Combinacion lineal\n",
    "    a_1 = tf.nn.relu(z_1) ##Funcion de activacion\n",
    "    \n",
    "   \n",
    "    z_2 = tf.matmul(a_1,W_2) + b_2 ##Combinacion lineal\n",
    "  \n",
    "    \n",
    "    return z_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de costo\n",
    "y_ = NN(x)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_,labels = y))\n",
    "\n",
    "\n",
    "#Predicciones\n",
    "train_pred = tf.nn.softmax(y_)#Predcciones en el conjunto de entrenamiento\n",
    "\n",
    "y_valid = NN(mnist.validation.images)\n",
    "valid_pred = tf.nn.softmax(y_valid) #Predicciones en el conjunto de validacion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizador\n",
    "opt = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sesion e inicializacion de variables\n",
    "\n",
    "sess = tf.Session()#creamos la session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def precision(predictions,labels):\n",
    "    return (100.0* np.sum(np.argmax(predictions,1)==np.argmax(labels,1))/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \n",
      "Costo del batch hasta el paso 0 es 8.695303\n",
      "Precision del conjunto de entrenamiento: 11.0%\n",
      "Precision del conjundo de validacion: 26.1%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 500 es 0.097808\n",
      "Precision del conjunto de entrenamiento: 97.0%\n",
      "Precision del conjundo de validacion: 96.0%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 1000 es 0.209466\n",
      "Precision del conjunto de entrenamiento: 94.0%\n",
      "Precision del conjundo de validacion: 96.8%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 1500 es 0.047680\n",
      "Precision del conjunto de entrenamiento: 98.0%\n",
      "Precision del conjundo de validacion: 97.3%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 2000 es 0.054323\n",
      "Precision del conjunto de entrenamiento: 99.0%\n",
      "Precision del conjundo de validacion: 97.3%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 2500 es 0.021931\n",
      "Precision del conjunto de entrenamiento: 99.0%\n",
      "Precision del conjundo de validacion: 97.6%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 3000 es 0.017982\n",
      "Precision del conjunto de entrenamiento: 100.0%\n",
      "Precision del conjundo de validacion: 97.8%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 3500 es 0.019119\n",
      "Precision del conjunto de entrenamiento: 99.0%\n",
      "Precision del conjundo de validacion: 97.7%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 4000 es 0.005899\n",
      "Precision del conjunto de entrenamiento: 100.0%\n",
      "Precision del conjundo de validacion: 97.8%\n",
      "\n",
      "\n",
      "Costo del batch hasta el paso 4500 es 0.003649\n",
      "Precision del conjunto de entrenamiento: 100.0%\n",
      "Precision del conjundo de validacion: 97.7%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Entrenamiento\n",
    "\n",
    "\n",
    "\n",
    "steps = 5000\n",
    "\n",
    "print('Training ')\n",
    "for i in range(steps):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _,cost, predictions = sess.run([opt,cross_entropy,train_pred], feed_dict={x: batch[0],y: batch[1]})\n",
    "    \n",
    "    if(i% 500 ==0):\n",
    "        print('Costo del batch hasta el paso %s es %f' %(i,cost))\n",
    "        print('Precision del conjunto de entrenamiento: %.1f%%' %precision(predictions,batch[1]))\n",
    "        print('Precision del conjundo de validacion: %.1f%%' %precision(valid_pred.eval(session=sess),mnist.validation.labels))\n",
    "        print('\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de prueba: 97.9%\n"
     ]
    }
   ],
   "source": [
    "y_test = NN(mnist.test.images)\n",
    "test_predictions = tf.nn.softmax(y_test)\n",
    "\n",
    "print('Precision del conjunto de prueba: %.1f%%' % precision(test_predictions.eval(session=sess),mnist.test.labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction =  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index = 600\n",
    "p = tf.argmax(NN(mnist.test.images[index:index+1]).eval(session = sess),1)\n",
    "print('prediction =  %s' %sess.run(p)[0])\n",
    "\n",
    "vis_img(index,conjunto='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "\n",
    "    # Only process if image has transparency \n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL \n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "\n",
    "        # Create a new background image of our matt color.\n",
    "        # Must be RGBA because paste requires both images have the same format\n",
    "\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_colour + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágen:./2hand.png\n",
      "Predicción: 2\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "imagen = \"./2hand.png\"\n",
    "img = Image.open(imagen)\n",
    "img = remove_transparency(img).convert('L')\n",
    "img = ImageOps.invert(img)\n",
    "if  img.size != (28,28):\n",
    "    img.thumbnail((28,28), Image.ANTIALIAS)\n",
    "\n",
    "entrada = np.array(img, dtype = np.float32)\n",
    "entrada = entrada.reshape((1,784))\n",
    "entrada = entrada/255.0\n",
    "        \n",
    "p = tf.argmax(NN(entrada).eval(session = sess),1)\n",
    "print(\"Imágen:{}\".format(imagen))\n",
    "img.show()\n",
    "print(\"Predicción:\", sess.run(p)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
